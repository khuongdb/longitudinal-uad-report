\chapter{Conclusion}
\label{chapter:conclusion}

\section{Summary}

In this internship project, we studied the application of diffusion models for \ac{UAD}, both in spatial and temporal contexts. Building on recent developments in diffusion models, we investigated the feasibility of addressing some of their critical limitations. First, we aimed to improve reconstruction quality by developing a mechanism that effectively conditions the diffusion process on the input image. To achieve this, we used a semantic encoder to extract a rich representation of the input, which is injected into our model using shift and scale operators. The benefits of our method are twofold. First, by avoiding direct concatenation of the input, we reduce the risk of data leakage, thereby preventing the model from simply memorizing the answer. Second, by employing the AdapGN mechanism, our model remains simpler than alternatives that rely on attention mechanisms or input concatenation. Finally, by choosing an appropriate noise level, our approach can correct anomalous regions while preserving the high-quality structure of healthy areas.

Next, we improved the performance of anomaly segmentation. Specially we focused on how to reduce false positive, which is a big challenge of reconstruction-based UAD methods. We demonstrated that classic quantile methods are not sufficient to deal with subtle anomalies, and their performance highly depends on the composition of the dataset. We introduced two modules: the feature attention module (FAM) and Longitudinal attention fusion module (LAFM) that align with \ac{UAD} principles: (i) they do not require labeled or ground truth train dataset to perform greedy search for best threshold, and (ii) they are robust to different data compositions. FAM is presented to incorporate structural similarities to eliminate residual error caused by model error. Additionally, LAFM leverages temporal information from multiple time points to further smooth the residual maps. LAFM accounts for the temporal persistence of anomalies, enabling the detection of subtle anomalies at earlier stages, under the assumption that they will also be present in future observations. Our model shows promising results and outperforms all previous quantile methods. Furthermore, both FAM and LAFM exhibit more stable performance across datasets with varying proportions of healthy and anomalous samples.

For longitudinal learning, we presented a temporal diffusion model and its capacities to generate future images based on current observed data. Even though we did not exploit TDM in the context of anomaly detection, our model effectively captures the residual progression of healthy patients across arbitrary time intervals. This validates the ability of diffusion models to learn longitudinal progression, and it serves as an immediate step for future development. 

\section{Limitation and future work}
\label{sec:limitation}

Despite showing promising result, our approach has certain limitations that can be improved in future work. First, our proposed fusion modules (FAM and LAFM) do not form a unified framework. Instead, their performance varies across different test cases and metrics. For example, FAM outperforms the other in reducing false positive segmentation, while LAFM is more effective in accurately segmenting true anomaly. In the case of image wise anomaly score, results suggests that raw pixel distance with automatic Yen threshold is the most effective strategy. We can switch between them to achieve optimal results, or use one as an initial mask for other, but it introduces more complexity into the post processing pipeline. Furthermore, our model is heavily curated for our synthetic dataset, which may introduce bias and risk of overfitting. More extensive evaluation is needed to assess the generalization capabilities of our model.

A key aspect we wish to emphasize is the spatio-temporal modeling, as it is the main target of our project. Even though we utilize temporal information to increase accuracy, we note that this functions more as a filtering/smoothing operation than as a statistical model. While our approach offers the benefit of training free (LAF module), it has major limitation in capturing temporal variability (population level) and spatial inter-variability (personal level). It is important to note that, in our model, each patient is processed independently, and we do not make use of shared information between patients. Our project is inspired by LVAE model of Sauty et al. \cite{SautyLongitudinalVAE2022}, in which they successfully impose mix effect model on the latent space of standard \ac{VAE}. By combining longitudinal learning with generative learning, LVAE offers a more powerful solution for progression modeling. One notable example is that LVAE can propagate both to the past or future, while our TDM can only generate future images. Also, LVAE operates similarly to a Gaussian process, it makes use of all available data to impute missing data, but our model currently can only take the most recent image as condition. We aim to apply the same principle of LVAE to diffusion model. There are other models motivated by the same principle. Chen et al. \cite{chenOrthogonalMixedEffectsModelingLongitudinal} use orthogonal linear transformation to disentangle global and individual trajectory, also apply to \ac{VAE} model. \cite{ca23LongitudinalNormalizingFlow} use normalizing flow to model temporal dependencies. The main challenge for such adaptation is that in \ac{VAE}, each sample corresponds to only one (normally non-spatial, low dimension) latent variable, while in \ac{DMs}, each sample (at one time point) has a sequence of spatial latent variables, and each latent variable is of same resolution as input. One avenue for future work is to view \ac{DMs} as a Hierarchical Variational Autoencoder (HVAE) \cite{luoUnderstandingDiffusionModels2022}, and impose longitudinal structure for every image at each noise level. It is apparent that this will increase the complexity of the model, and require large number of epochs to train (one full epoch requires the model to see all samples with all noise steps). Nevertheless, it can serve as a starting point for further improvements. 

Another direction we want to explore is to exploit the stochastic subcodes obtained from the reversed DDIM sampling scheme, which we have shown to contain fine-grained details of the original inputs and to deviate from a strict normal distribution. It would be interesting to investigate whether the divergence between these distributions and a standard Gaussian (e.g., measured via KL divergence) can be leveraged for anomaly detection. One thing to note is that in principle, this is very similar to score-based \ac{UAD} \cite{wangEPDiffErasurePerception2025,pinaya2022fastUAD-DDPM}, which is another family of UAD with diffusion models. 

We conduct our experiment on synthetic 2D dataset at a low resolution, so the results can be very different from real world 3D MRI scans, specially with anomalies that are very subtle. We aim to adapt and evaluate our model on PPMI dataset \cite{mcs+18PPMIParkinsonsProgressionMarkers}. To effectively transfer our model to PPMI dataset, one common approach is to apply 2D diffusion models slice-wise on 3D scans, and then concatenate results together to reconstruct 3D volumes. This comes with limitation of missing 3D context and spatial relationships between slices. Another approach is to compress original 3D input into latent variable \cite{rombachLDM,puglisiBrLP,lozuponeLDAE2025}, and then train \ac{DMs} on this latent variable. To best preserve the signal from original 3D volume, the most effective approach would be to implement 3D diffusion models. We can explore the option of training only on patches to address the problem of high memory requirements and computational. 

% At the time of this writing, we are still experimenting with some of the aforementioned improvements, particularly in modeling the longitudinal diffusion process as a hierarchical variational autoencoder.

% The disadvantage of this approach is that compresion model (e.g. AE-KL) acts as a bottle neck of the model. 

